{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##Project Preliminary Data Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###Problem Statement and Background (2 points)\n",
    "A high-level statement of the problem you intend to address, e.g. finding correspondences between neural recordings and DNN layers. Try to translate the high-level into specific questions if you can.\n",
    "Give background on the problem you are solving: why it is interesting, who is interested, what is known, some references about it, etc."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###The Data Source(s) You Are Using (2 points)\n",
    "Describe the data source(s) you have. How much data you have now, and how much you expect to use for your final analysis. We will need that information soon so we can get the necessary data to you."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###Data Joining/Cleaning You Did (4 points)\n",
    "If data is being joined, describe the joining process and any problems with it - explain the metric used for fuzzy joins.\n",
    "Explain how you will handle missing or duplicate keys. Describe the tools you used to examine/repair/clean the data.\n",
    "If you found any statistical anomalies last time, explain how you plan to deal with them.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "import sys\n",
    "import os\n",
    "import numpy as np\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Load Biz Dataset into DF\n",
    "biz_data = []\n",
    "biz_fn = 'yelp_dataset_challenge_academic_dataset/yelp_academic_dataset_business.json'\n",
    "with open(biz_fn) as data_file:\n",
    "    for line in data_file:\n",
    "        biz_data.append(json.loads(line))\n",
    "biz_df = pd.DataFrame(biz_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#filtering businesses into restaurants\n",
    "category_csv = 'restaurantcategories.csv'\n",
    "all_categories = []\n",
    "restaurants = []\n",
    "with open(category_csv) as categories:\n",
    "    for line in categories:\n",
    "        all_categories.append(line)\n",
    "biz_dict = biz_df.to_dict()\n",
    "all_categories = all_categories[0].split('\\r')\n",
    "for index in biz_dict['categories'].keys():\n",
    "    if len(biz_dict['categories'][index]) == 0:\n",
    "        for col in biz_dict.keys():\n",
    "                del biz_dict[col][index] \n",
    "    elif len(biz_dict['categories'][index]) > 0:\n",
    "        allInCats = True\n",
    "        for elem in biz_dict['categories'][index]:\n",
    "            if elem not in all_categories:\n",
    "                allInCats = False\n",
    "                break;\n",
    "        if not allInCats:\n",
    "            for col in biz_dict.keys():\n",
    "                del biz_dict[col][index] \n",
    "                \n",
    "res_df = pd.DataFrame(biz_dict)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Load review dataset into df\n",
    "review_data = []\n",
    "review_fn = 'yelp_dataset_challenge_academic_dataset/yelp_academic_dataset_review.json'\n",
    "with open(review_fn) as data_file:\n",
    "    for line in data_file:\n",
    "        review_data.append(json.loads(line))\n",
    "review_df = pd.DataFrame(review_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###Analysis Approach (3 points)\n",
    "Describe what analysis you are doing: This will probably comprise:\n",
    "Featurization: Explain how you generated features from the raw data. e.g. thresholding to produce binary features, binning, tf-idf, multinomial -> multiple binary features (one-hot encoding). Describe any value transformations you did, e.g. histogram normalization.\n",
    "Modeling: Which machine learning models did you try? Which do you plan to try in the future?\n",
    "Performance measurement: How will you evaluate your model and improve featurization etc."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###Preliminary Results (6 Points)\n",
    "Summarize the results you have so far:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
